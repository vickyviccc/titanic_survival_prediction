{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a83162d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-17T06:49:16.044852Z",
     "iopub.status.busy": "2024-10-17T06:49:16.044451Z",
     "iopub.status.idle": "2024-10-17T06:49:16.950828Z",
     "shell.execute_reply": "2024-10-17T06:49:16.949508Z"
    },
    "papermill": {
     "duration": 0.915381,
     "end_time": "2024-10-17T06:49:16.953563",
     "exception": false,
     "start_time": "2024-10-17T06:49:16.038182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "# ------------------\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47ba44d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T06:49:16.963841Z",
     "iopub.status.busy": "2024-10-17T06:49:16.963306Z",
     "iopub.status.idle": "2024-10-17T06:49:17.005497Z",
     "shell.execute_reply": "2024-10-17T06:49:17.004300Z"
    },
    "papermill": {
     "duration": 0.050123,
     "end_time": "2024-10-17T06:49:17.008040",
     "exception": false,
     "start_time": "2024-10-17T06:49:16.957917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff07d0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T06:49:17.018203Z",
     "iopub.status.busy": "2024-10-17T06:49:17.017784Z",
     "iopub.status.idle": "2024-10-17T06:49:17.038612Z",
     "shell.execute_reply": "2024-10-17T06:49:17.037471Z"
    },
    "papermill": {
     "duration": 0.028941,
     "end_time": "2024-10-17T06:49:17.041286",
     "exception": false,
     "start_time": "2024-10-17T06:49:17.012345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58701938",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T06:49:17.051956Z",
     "iopub.status.busy": "2024-10-17T06:49:17.051575Z",
     "iopub.status.idle": "2024-10-17T06:49:17.064244Z",
     "shell.execute_reply": "2024-10-17T06:49:17.063079Z"
    },
    "papermill": {
     "duration": 0.02041,
     "end_time": "2024-10-17T06:49:17.066250",
     "exception": false,
     "start_time": "2024-10-17T06:49:17.045840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of women who survived: 0.7420382165605095\n"
     ]
    }
   ],
   "source": [
    "women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\n",
    "rate_women = sum(women)/len(women)\n",
    "\n",
    "print(\"% of women who survived:\", rate_women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfbdf787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T06:49:17.077099Z",
     "iopub.status.busy": "2024-10-17T06:49:17.076283Z",
     "iopub.status.idle": "2024-10-17T06:49:17.083784Z",
     "shell.execute_reply": "2024-10-17T06:49:17.082701Z"
    },
    "papermill": {
     "duration": 0.015413,
     "end_time": "2024-10-17T06:49:17.086038",
     "exception": false,
     "start_time": "2024-10-17T06:49:17.070625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of men who survived: 0.18890814558058924\n"
     ]
    }
   ],
   "source": [
    "men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\n",
    "rate_men = sum(men)/len(men)\n",
    "\n",
    "print(\"% of men who survived:\", rate_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "637ac9a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T06:49:17.096836Z",
     "iopub.status.busy": "2024-10-17T06:49:17.095919Z",
     "iopub.status.idle": "2024-10-17T06:49:19.060575Z",
     "shell.execute_reply": "2024-10-17T06:49:19.059487Z"
    },
    "papermill": {
     "duration": 1.97317,
     "end_time": "2024-10-17T06:49:19.063613",
     "exception": false,
     "start_time": "2024-10-17T06:49:17.090443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y = train_data[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X = pd.get_dummies(train_data[features])\n",
    "X_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ef0e88a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T06:49:19.078955Z",
     "iopub.status.busy": "2024-10-17T06:49:19.077896Z",
     "iopub.status.idle": "2024-10-17T06:49:19.083372Z",
     "shell.execute_reply": "2024-10-17T06:49:19.082397Z"
    },
    "papermill": {
     "duration": 0.015751,
     "end_time": "2024-10-17T06:49:19.086025",
     "exception": false,
     "start_time": "2024-10-17T06:49:19.070274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine (SVM) Model\n",
    "# ----------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03e81a8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T06:49:19.099139Z",
     "iopub.status.busy": "2024-10-17T06:49:19.098106Z",
     "iopub.status.idle": "2024-10-17T06:49:19.188664Z",
     "shell.execute_reply": "2024-10-17T06:49:19.187394Z"
    },
    "papermill": {
     "duration": 0.099117,
     "end_time": "2024-10-17T06:49:19.191101",
     "exception": false,
     "start_time": "2024-10-17T06:49:19.091984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8045\n",
      "Submission file saved as svm_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Drop unnecessary columns from the training data\n",
    "X = train_data.drop(['Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "y = train_data['Survived']\n",
    "\n",
    "# Fill missing values for numeric columns in the training data\n",
    "numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n",
    "\n",
    "# One-hot encode categorical variables like 'Sex', 'Embarked'\n",
    "X = pd.get_dummies(X, columns=['Sex', 'Embarked'])\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features (SVM works better with scaled data)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Create and train the SVM model\n",
    "svm_model = SVC(kernel='rbf', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = svm_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Preprocess the test data for prediction\n",
    "X_test = test_data.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# Fill missing values for numeric columns in the test data\n",
    "numeric_cols_test = X_test.select_dtypes(include=['float64', 'int64']).columns\n",
    "X_test[numeric_cols_test] = X_test[numeric_cols_test].fillna(X_test[numeric_cols_test].mean())\n",
    "\n",
    "# One-hot encode categorical variables in the test data\n",
    "X_test = pd.get_dummies(X_test, columns=['Sex', 'Embarked'])\n",
    "\n",
    "# Ensure that the columns in the test set match the training set\n",
    "X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Scale the test data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Prepare the submission file for Kaggle\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "# Save the submission to a CSV file\n",
    "submission.to_csv('svm_submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file saved as svm_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b829687a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T06:49:19.203092Z",
     "iopub.status.busy": "2024-10-17T06:49:19.201874Z",
     "iopub.status.idle": "2024-10-17T06:49:19.563585Z",
     "shell.execute_reply": "2024-10-17T06:49:19.562149Z"
    },
    "papermill": {
     "duration": 0.370342,
     "end_time": "2024-10-17T06:49:19.566136",
     "exception": false,
     "start_time": "2024-10-17T06:49:19.195794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (Ensemble): 0.8156\n",
      "Submission file saved as ensemble_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Assuming you've already preprocessed your data (X_train, X_val, y_train, y_val, X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Train SVM model (with probability enabled)\n",
    "svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Get probability predictions from both models for the validation set\n",
    "rf_proba_val = rf_model.predict_proba(X_val)\n",
    "svm_proba_val = svm_model.predict_proba(X_val)\n",
    "\n",
    "# Average the probabilities\n",
    "avg_proba_val = (rf_proba_val + svm_proba_val) / 2\n",
    "\n",
    "# Convert averaged probabilities to final predictions\n",
    "final_predictions_val = np.argmax(avg_proba_val, axis=1)\n",
    "\n",
    "# Evaluate ensemble on validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_val, final_predictions_val)\n",
    "print(f'Validation Accuracy (Ensemble): {accuracy:.4f}')\n",
    "\n",
    "# Repeat for the test data\n",
    "rf_proba_test = rf_model.predict_proba(X_test)\n",
    "svm_proba_test = svm_model.predict_proba(X_test)\n",
    "\n",
    "# Average the test set probabilities\n",
    "avg_proba_test = (rf_proba_test + svm_proba_test) / 2\n",
    "\n",
    "# Final predictions for the test set\n",
    "final_predictions_test = np.argmax(avg_proba_test, axis=1)\n",
    "\n",
    "# Prepare the submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],\n",
    "    'Survived': final_predictions_test\n",
    "})\n",
    "submission.to_csv('ensemble_submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file saved as ensemble_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "add55b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T06:49:19.578818Z",
     "iopub.status.busy": "2024-10-17T06:49:19.578309Z",
     "iopub.status.idle": "2024-10-17T06:49:19.943998Z",
     "shell.execute_reply": "2024-10-17T06:49:19.942863Z"
    },
    "papermill": {
     "duration": 0.375524,
     "end_time": "2024-10-17T06:49:19.946458",
     "exception": false,
     "start_time": "2024-10-17T06:49:19.570934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (Stacking): 0.8324\n",
      "Submission file saved as stacking_submission.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train both models on the training set\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Get the predictions from both models on the validation set\n",
    "rf_proba_val = rf_model.predict_proba(X_val)\n",
    "svm_proba_val = svm_model.predict_proba(X_val)\n",
    "\n",
    "# Stack the predictions horizontally\n",
    "stacked_val_predictions = np.hstack((rf_proba_val, svm_proba_val))\n",
    "\n",
    "# Train a meta-model (logistic regression) on the stacked predictions\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(stacked_val_predictions, y_val)\n",
    "\n",
    "# Test meta-model on validation set\n",
    "final_predictions_val = meta_model.predict(stacked_val_predictions)\n",
    "\n",
    "# Evaluate the meta-model on the validation set\n",
    "accuracy = accuracy_score(y_val, final_predictions_val)\n",
    "print(f'Validation Accuracy (Stacking): {accuracy:.4f}')\n",
    "\n",
    "# Now, for the test set:\n",
    "rf_proba_test = rf_model.predict_proba(X_test)\n",
    "svm_proba_test = svm_model.predict_proba(X_test)\n",
    "\n",
    "# Stack the predictions for the test set\n",
    "stacked_test_predictions = np.hstack((rf_proba_test, svm_proba_test))\n",
    "\n",
    "# Use the meta-model to predict the final outcomes on the test set\n",
    "final_predictions_test = meta_model.predict(stacked_test_predictions)\n",
    "\n",
    "# Prepare the submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],\n",
    "    'Survived': final_predictions_test\n",
    "})\n",
    "submission.to_csv('stacking_submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file saved as stacking_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "145bd152",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T06:49:19.958470Z",
     "iopub.status.busy": "2024-10-17T06:49:19.957854Z",
     "iopub.status.idle": "2024-10-17T06:49:20.195387Z",
     "shell.execute_reply": "2024-10-17T06:49:20.193894Z"
    },
    "papermill": {
     "duration": 0.246557,
     "end_time": "2024-10-17T06:49:20.197946",
     "exception": false,
     "start_time": "2024-10-17T06:49:19.951389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filling NaNs in numeric columns of test_data:\n",
      "PassengerId        0\n",
      "Pclass             0\n",
      "Name               0\n",
      "Sex                0\n",
      "Age                0\n",
      "SibSp              0\n",
      "Parch              0\n",
      "Ticket             0\n",
      "Fare               0\n",
      "Cabin            327\n",
      "Embarked           0\n",
      "FamilySize         0\n",
      "IsAlone            0\n",
      "FarePerPerson      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/4274264860.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data['Age'].fillna(train_data['Age'].median(), inplace=True)\n",
      "/tmp/ipykernel_17/4274264860.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data['Fare'].fillna(train_data['Fare'].median(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8436\n",
      "Submission file saved as gradient_boosting_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset from Kaggle's input directory\n",
    "train_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "# 1. Create FamilySize feature\n",
    "train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1\n",
    "\n",
    "# 2. Create IsAlone feature\n",
    "train_data['IsAlone'] = 1\n",
    "train_data.loc[train_data['FamilySize'] > 1, 'IsAlone'] = 0\n",
    "test_data['IsAlone'] = 1\n",
    "test_data.loc[test_data['FamilySize'] > 1, 'IsAlone'] = 0\n",
    "\n",
    "# 4. Create FarePerPerson feature\n",
    "train_data['FarePerPerson'] = train_data['Fare'] / train_data['FamilySize']\n",
    "test_data['FarePerPerson'] = test_data['Fare'] / test_data['FamilySize']\n",
    "\n",
    "# Handle missing values in training data using the median\n",
    "train_data['Age'].fillna(train_data['Age'].median(), inplace=True)\n",
    "train_data['Fare'].fillna(train_data['Fare'].median(), inplace=True)\n",
    "\n",
    "# Handle missing values in test data for numeric columns only\n",
    "numeric_columns = test_data.select_dtypes(include=[np.number]).columns\n",
    "test_data[numeric_columns] = test_data[numeric_columns].fillna(test_data[numeric_columns].median())\n",
    "\n",
    "# Check for any remaining missing values in the test data\n",
    "print(\"After filling NaNs in numeric columns of test_data:\")\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "# Drop non-numeric columns like 'Name', 'Ticket', 'Cabin' if present\n",
    "train_data = train_data.drop(['Name', 'Ticket', 'Cabin'], axis=1, errors='ignore')\n",
    "test_data = test_data.drop(['Name', 'Ticket', 'Cabin'], axis=1, errors='ignore')\n",
    "\n",
    "# One-hot encode categorical features in both train and test datasets\n",
    "train_data = pd.get_dummies(train_data, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "# Ensure both datasets have the same columns (this accounts for any differences in dummy variables)\n",
    "test_data = test_data.reindex(columns=train_data.columns.drop('Survived'), fill_value=0)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = train_data.drop('Survived', axis=1)\n",
    "y = train_data['Survived']\n",
    "\n",
    "# Train-Test Split for evaluation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = gb_model.predict(X_val)\n",
    "\n",
    "# Calculate validation accuracy\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Predict on the test data after ensuring no missing values\n",
    "test_predictions = gb_model.predict(test_data)\n",
    "\n",
    "# Prepare the submission file using correct PassengerId from the test set\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': pd.read_csv('/kaggle/input/titanic/test.csv')['PassengerId'],  # Ensure the PassengerId is from the test set\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('gradient_boosting_submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file saved as gradient_boosting_submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.597906,
   "end_time": "2024-10-17T06:49:20.825703",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-17T06:49:13.227797",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
